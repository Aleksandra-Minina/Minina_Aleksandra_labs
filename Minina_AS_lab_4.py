# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zyG6LExXA8DM-fo5FwrPwcz9ZGkbpD0i
"""

from google.colab import files
uploaded = files.upload()

from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score # Import f1_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

def classification_training(data):
    # 2. Inside the function, add the code to create the binary target variable 'mental_wellness_binary'
    data['mental_wellness_binary'] = (data['mental_wellness_index_0_100'] >= 15).astype(int)
    print("Функция запущена! Размер датасета:", data.shape)
    print("Столбец 'mental_wellness_binary' добавлен.")
    print(data[['mental_wellness_index_0_100', 'mental_wellness_binary']].head())

    # 3. Define the features X and the target y
    X = data.drop(columns=['user_id', 'mental_wellness_index_0_100', 'mental_wellness_binary'])
    y = data['mental_wellness_binary']

    # 4. Split X and y into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    print("\nРазмер X_train:", X_train.shape)
    print("Размер X_test:", X_test.shape)
    print("Размер y_train:", y_train.shape)
    print("Размер y_test:", y_test.shape)


    # 5. Define the categorical and numerical features
    categorical_features = ['gender', 'occupation', 'work_mode']
    numerical_features = [col for col in X_train.columns if col not in categorical_features]


    # 6. Create a ColumnTransformer named preprocessor
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('passthrough', 'passthrough')]), numerical_features),
            ('cat', Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)
        ],
        remainder='drop'
    )

    # 7. Create a Pipeline named svm_pipeline
    svm_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                   ('classifier', SVC(random_state=42))])

    # 8. Create a Pipeline named lr_pipeline
    lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                  ('classifier', LogisticRegression(random_state=42, max_iter=1000))])

    # 9. Fit both svm_pipeline and lr_pipeline to the training data
    svm_pipeline.fit(X_train, y_train)
    lr_pipeline.fit(X_train, y_train)
    print("\nМодели SVM и логистической регрессии обучены.")

    # 10. Make predictions on the test set
    y_pred_svm = svm_pipeline.predict(X_test)
    y_pred_lr = lr_pipeline.predict(X_test)
    print("Предсказания сделаны.")

    # 11. Calculate the accuracy and f1-score
    accuracy_svm = accuracy_score(y_test, y_pred_svm)
    f1_svm = f1_score(y_test, y_pred_svm)

    accuracy_lr = accuracy_score(y_test, y_pred_lr)
    f1_lr = f1_score(y_test, y_pred_lr)

    # 12. Print the accuracy and f1-score
    print(f"SVM: {accuracy_svm:.4f}; {f1_svm:.4f}")
    print(f"Logistic Regression: {accuracy_lr:.4f}; {f1_lr:.4f}")

    # 13. Ensure the function does not have a return statement (implicitly handled)

# Call the modified function
classification_training(data.copy()) # Pass a copy to avoid modifying the original dataframe if needed later

